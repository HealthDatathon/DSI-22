{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Detection of Covid Positive Cases using Image Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/HealthDatathon/DSI-22/blob/main/notebooks//covid-cxr/detection-of-covid-positive-cases-using-dl.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-21T11:28:57.88204Z",
     "iopub.status.busy": "2022-02-21T11:28:57.881693Z",
     "iopub.status.idle": "2022-02-21T11:28:57.906122Z",
     "shell.execute_reply": "2022-02-21T11:28:57.905489Z",
     "shell.execute_reply.started": "2022-02-21T11:28:57.88193Z"
    }
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "    <body>\n",
    "        <iframe src = \"https://atharv-chaudhari.github.io/Project-Covid-Cache/\" height = \"650px\" width = \"100%\">\n",
    "        </iframe>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> COVID-19 tests are currently hard to come by â€” there are simply not enough of them and they cannot be manufactured fast enough, which is causing panic.\n",
    "\n",
    "> Given that there are limited COVID-19 testing kits, we need to rely on other diagnosis measures.\n",
    "\n",
    "> We thought to explore X-ray images as doctors frequently use X-rays and CT scans to diagnose pneumonia, lung inflammation, abscesses, and/or enlarged lymph nodes.\n",
    "\n",
    "> Since COVID-19 attacks the epithelial cells that line our respiratory tract, we can use X-rays to analyze the health of a patientâ€™s lungs.\n",
    "\n",
    "<div style=\"width:100%;text-align: center;\"> \n",
    "    <img align=middle src=\"https://upload.wikimedia.org/wikipedia/commons/7/72/Projectional_rendering_of_CT_scan_of_thorax_%28thumbnail%29.gif\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Data Source](https://www.kaggle.com/tawsifurrahman/covid19-radiography-database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Required Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:28:57.908144Z",
     "iopub.status.busy": "2022-02-21T11:28:57.90767Z",
     "iopub.status.idle": "2022-02-21T11:29:06.180794Z",
     "shell.execute_reply": "2022-02-21T11:29:06.180077Z",
     "shell.execute_reply.started": "2022-02-21T11:28:57.908108Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Data Reading \n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Data Processing \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import random\n",
    "import albumentations as A\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Modeling & Model Evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, recall_score, accuracy_score, precision_score, f1_score\n",
    "\n",
    "# Grad-CAM\n",
    "\n",
    "import keras\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:29:06.184263Z",
     "iopub.status.busy": "2022-02-21T11:29:06.183719Z",
     "iopub.status.idle": "2022-02-21T11:29:06.689837Z",
     "shell.execute_reply": "2022-02-21T11:29:06.689142Z",
     "shell.execute_reply.started": "2022-02-21T11:29:06.184223Z"
    }
   },
   "outputs": [],
   "source": [
    "levels = ['Normal', 'COVID']\n",
    "path = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset\"\n",
    "data_dir = os.path.join(path)\n",
    "\n",
    "data = []\n",
    "for id, level in enumerate(levels):\n",
    "    for file in os.listdir(os.path.join(data_dir, level)):\n",
    "        data.append(['{}/{}'.format(level, file), level])\n",
    "\n",
    "data = pd.DataFrame(data, columns = ['image_file', 'corona_result'])\n",
    "\n",
    "data['path'] = path + '/' + data['image_file']\n",
    "data['corona_result'] = data['corona_result'].map({'Normal': 'Negative', 'COVID': 'Positive'})\n",
    "samples = 13808\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:29:06.691558Z",
     "iopub.status.busy": "2022-02-21T11:29:06.691146Z",
     "iopub.status.idle": "2022-02-21T11:29:06.715583Z",
     "shell.execute_reply": "2022-02-21T11:29:06.714736Z",
     "shell.execute_reply.started": "2022-02-21T11:29:06.69152Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of Duplicated Samples: %d'%(data.duplicated().sum()))\n",
    "print('Number of Total Samples: %d'%(data.isnull().value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:29:06.718247Z",
     "iopub.status.busy": "2022-02-21T11:29:06.717968Z",
     "iopub.status.idle": "2022-02-21T11:29:07.357498Z",
     "shell.execute_reply": "2022-02-21T11:29:07.356844Z",
     "shell.execute_reply.started": "2022-02-21T11:29:06.718212Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['corona_result'] = ['Positive', 'Negative']\n",
    "df['Count'] = [len(data[data['corona_result'] == 'Positive']), len(data[data['corona_result'] == 'Negative'])]\n",
    "df = df.sort_values(by = ['Count'], ascending = False)\n",
    "\n",
    "fig = px.bar(df, x = 'corona_result', y = 'Count', \n",
    "             color = \"corona_result\", text_auto='', width = 600, \n",
    "             color_discrete_sequence = [\"orange\", \"purple\"],\n",
    "             template = 'plotly_dark')\n",
    "\n",
    "fig.update_xaxes(showgrid = False)\n",
    "fig.update_yaxes(showgrid = False)\n",
    "fig.update_traces(textfont_size = 12, textangle = 0, textposition = \"outside\", cliponaxis = False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:29:07.359388Z",
     "iopub.status.busy": "2022-02-21T11:29:07.358922Z",
     "iopub.status.idle": "2022-02-21T11:31:04.464603Z",
     "shell.execute_reply": "2022-02-21T11:31:04.463895Z",
     "shell.execute_reply.started": "2022-02-21T11:29:07.359351Z"
    }
   },
   "outputs": [],
   "source": [
    "data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((75,75))))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:04.466282Z",
     "iopub.status.busy": "2022-02-21T11:31:04.465745Z",
     "iopub.status.idle": "2022-02-21T11:31:05.331496Z",
     "shell.execute_reply": "2022-02-21T11:31:05.328101Z",
     "shell.execute_reply.started": "2022-02-21T11:31:04.466249Z"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 3\n",
    "\n",
    "fig, m_axs = plt.subplots(2, n_samples, figsize = (6*n_samples, 3*4))\n",
    "\n",
    "for n_axs, (type_name, type_rows) in zip(m_axs, data.sort_values(['corona_result']).groupby('corona_result')):\n",
    "    n_axs[1].set_title(type_name, fontsize = 15)\n",
    "    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state = 1234).iterrows()):       \n",
    "        picture = c_row['path']\n",
    "        image = cv2.imread(picture)\n",
    "        c_ax.imshow(image)\n",
    "        c_ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:05.332676Z",
     "iopub.status.busy": "2022-02-21T11:31:05.332457Z",
     "iopub.status.idle": "2022-02-21T11:31:05.449037Z",
     "shell.execute_reply": "2022-02-21T11:31:05.448342Z",
     "shell.execute_reply.started": "2022-02-21T11:31:05.332647Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "image = cv2.imread(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/COVID-1002.png\")\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:05.45104Z",
     "iopub.status.busy": "2022-02-21T11:31:05.450568Z",
     "iopub.status.idle": "2022-02-21T11:31:05.463357Z",
     "shell.execute_reply": "2022-02-21T11:31:05.462444Z",
     "shell.execute_reply.started": "2022-02-21T11:31:05.450989Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Image Shape: {}'.format(image.shape))\n",
    "print('Image Height: {}'.format(image.shape[0]))\n",
    "print('Image Width: {}'.format(image.shape[1]))\n",
    "print('Image Dimension: {}'.format(image.ndim))\n",
    "print('Image Size: {}kb'.format(image.size//1024))\n",
    "print('Image Data Type: {}'.format(image.dtype))\n",
    "print('Maximum RGB value of the image: {}'.format(image.max()))\n",
    "print('Minimum RGB value of the image: {}'.format(image.min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We observe that the image has 3 channels, hence it in in RGB scale even if these are X-ray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. B-Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:05.465629Z",
     "iopub.status.busy": "2022-02-21T11:31:05.465157Z",
     "iopub.status.idle": "2022-02-21T11:31:05.60408Z",
     "shell.execute_reply": "2022-02-21T11:31:05.603376Z",
     "shell.execute_reply.started": "2022-02-21T11:31:05.465592Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.title('B channel', fontsize = 14)\n",
    "plt.imshow(image[ : , : , 0])\n",
    "plt.axis('off');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Ben Graham's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, we convert the images to greyscale and then apply Gaussian blur to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:05.608147Z",
     "iopub.status.busy": "2022-02-21T11:31:05.607704Z",
     "iopub.status.idle": "2022-02-21T11:31:05.681045Z",
     "shell.execute_reply": "2022-02-21T11:31:05.68041Z",
     "shell.execute_reply.started": "2022-02-21T11:31:05.608112Z"
    }
   },
   "outputs": [],
   "source": [
    "all_covid = []\n",
    "all_normal = []\n",
    "\n",
    "all_normal.extend(glob(os.path.join(path, \"Normal/*.png\")))\n",
    "all_covid.extend(glob(os.path.join(path, \"COVID/*.png\")))\n",
    "\n",
    "random.shuffle(all_normal)\n",
    "random.shuffle(all_covid)\n",
    "\n",
    "images = all_normal[:50] + all_covid[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:05.682368Z",
     "iopub.status.busy": "2022-02-21T11:31:05.682135Z",
     "iopub.status.idle": "2022-02-21T11:31:10.296435Z",
     "shell.execute_reply": "2022-02-21T11:31:10.295801Z",
     "shell.execute_reply.started": "2022-02-21T11:31:05.682335Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18, 7))\n",
    "fig.suptitle(\"Ben Grahamns Method of Analysis\", fontsize = 15)\n",
    "columns = 4; rows = 2\n",
    "\n",
    "for i in range(1, columns*rows +1):\n",
    "    img = cv2.imread(images[i])\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    img = cv2.addWeighted (img, 4, cv2.GaussianBlur(img, (0,0), 512/10), -4, 128)\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.imshow(img)\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Albumentations Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:10.297857Z",
     "iopub.status.busy": "2022-02-21T11:31:10.297511Z",
     "iopub.status.idle": "2022-02-21T11:31:10.309975Z",
     "shell.execute_reply": "2022-02-21T11:31:10.309122Z",
     "shell.execute_reply.started": "2022-02-21T11:31:10.297826Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_multiple_img(img_matrix_list, title_list, ncols, main_title = \"\"):\n",
    "    \n",
    "    fig, myaxes = plt.subplots(figsize = (15, 8), nrows = 2, ncols = ncols, squeeze = False)\n",
    "    fig.suptitle(main_title, fontsize = 18)\n",
    "    fig.subplots_adjust(wspace = 0.3)\n",
    "    fig.subplots_adjust(hspace = 0.3)\n",
    "    \n",
    "    for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n",
    "        myaxes[i // ncols][i % ncols].imshow(img)\n",
    "        myaxes[i // ncols][i % ncols].set_title(title, fontsize = 15)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:10.311122Z",
     "iopub.status.busy": "2022-02-21T11:31:10.310908Z",
     "iopub.status.idle": "2022-02-21T11:31:11.390544Z",
     "shell.execute_reply": "2022-02-21T11:31:11.389851Z",
     "shell.execute_reply.started": "2022-02-21T11:31:10.311099Z"
    }
   },
   "outputs": [],
   "source": [
    "chosen_image = cv2.imread(\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/COVID-1002.png\")\n",
    "\n",
    "albumentation_list = [A.RandomFog(p = 1), A.RandomBrightness(p = 1),\n",
    "                      A.RandomCrop(p = 1,height = 199, width = 199), A.Rotate(p = 1, limit = 90),\n",
    "                      A.RGBShift(p = 1), A.VerticalFlip(p = 1), A.RandomContrast(limit = 0.5, p = 1)]\n",
    "\n",
    "img_matrix_list = []\n",
    "bboxes_list = []\n",
    "for aug_type in albumentation_list:\n",
    "    img = aug_type(image = chosen_image)['image']\n",
    "    img_matrix_list.append(img)\n",
    "\n",
    "img_matrix_list.insert(0,chosen_image)    \n",
    "\n",
    "titles_list = [\"Original\", \"RandomFog\", \"RandomBrightness\", \"RandomCrop\", \"Rotate\", \"RGBShift\", \"VerticalFlip\", \"RandomContrast\"]\n",
    "\n",
    "plot_multiple_img(img_matrix_list, titles_list, ncols = 4, main_title = \"Different Types of Augmentations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Image Value Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:11.392372Z",
     "iopub.status.busy": "2022-02-21T11:31:11.39194Z",
     "iopub.status.idle": "2022-02-21T11:31:12.96872Z",
     "shell.execute_reply": "2022-02-21T11:31:12.967944Z",
     "shell.execute_reply.started": "2022-02-21T11:31:11.392338Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_val = []\n",
    "std_dev_val = []\n",
    "max_val = []\n",
    "min_val = []\n",
    "\n",
    "for i in range(0, samples):\n",
    "    mean_val.append(data['image'][i].mean())\n",
    "    std_dev_val.append(np.std(data['image'][i]))\n",
    "    max_val.append(data['image'][i].max())\n",
    "    min_val.append(data['image'][i].min())\n",
    "\n",
    "imageEDA = data.loc[:,['image','corona_result','path']]\n",
    "imageEDA['mean'] = mean_val\n",
    "imageEDA['stedev'] = std_dev_val\n",
    "imageEDA['max'] = max_val\n",
    "imageEDA['min'] = min_val\n",
    "\n",
    "imageEDA['subt_mean'] = imageEDA['mean'].mean() - imageEDA['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:12.97055Z",
     "iopub.status.busy": "2022-02-21T11:31:12.970273Z",
     "iopub.status.idle": "2022-02-21T11:31:14.426429Z",
     "shell.execute_reply": "2022-02-21T11:31:14.425173Z",
     "shell.execute_reply.started": "2022-02-21T11:31:12.970512Z"
    }
   },
   "outputs": [],
   "source": [
    "ax1 = sns.displot(data = imageEDA, x = 'mean', kind=\"kde\", hue = 'corona_result');\n",
    "plt.title('Images Colour Mean Value Distribution by Class\\n', fontsize = 12);\n",
    "\n",
    "ax2 = sns.displot(data = imageEDA, x = 'max', kind=\"kde\", hue = 'corona_result');\n",
    "plt.title('\\nImages Colour Max Value Distribution by Class\\n', fontsize = 12);\n",
    "\n",
    "ax3 = sns.displot(data = imageEDA, x = 'min', kind=\"kde\", hue = 'corona_result');\n",
    "plt.title('\\nImages Colour Min Value Distribution by Class\\n', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Mean vs Density plot insights for pixels:\n",
    "> 1. The max pixel value for Covid Negative cases is greater than 0.014 and less than 0.016.\n",
    "> 2. The max pixel value for Covid Positive cases is greater than 0.004 & less than 0.006.\n",
    "\n",
    "> The Max vs Density plot insights for pixels:\n",
    "> 1. The max pixel value for Covid Negative cases is greater than 0.035 and less than 0.040.\n",
    "> 2. The max pixel value for Covid Positive cases is 0.005.\n",
    "\n",
    "> The Min vs Density plot insights for pixels:\n",
    "> 1. The max pixel value for Covid Negative cases is greater than 0.4.\n",
    "> 2. The max pixel value for Covid Positive cases is greater than 0.0 and less than 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:14.428111Z",
     "iopub.status.busy": "2022-02-21T11:31:14.427676Z",
     "iopub.status.idle": "2022-02-21T11:31:15.443537Z",
     "shell.execute_reply": "2022-02-21T11:31:15.442927Z",
     "shell.execute_reply.started": "2022-02-21T11:31:14.428075Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20, 8))\n",
    "sns.set(style = \"ticks\", font_scale = 1)\n",
    "ax = sns.scatterplot(data = imageEDA, x = \"mean\", y = imageEDA['stedev'], hue = 'corona_result', alpha = 0.8);\n",
    "sns.despine(top = True, right = True, left = False, bottom = False)\n",
    "plt.xticks(rotation = 0, fontsize = 12)\n",
    "ax.set_xlabel('\\nImage Channel Colour Mean', fontsize = 14)\n",
    "ax.set_ylabel('Image Channel Colour Standard Deviation', fontsize = 14)\n",
    "plt.title('Mean and Standard Deviation of Image Samples', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We observe that there are 2 clusters formed, one for Covid Positive, one for Covid Negative and both have several overlappings. Overlapping Color Mean range: (100 - 175)\n",
    "\n",
    "> We observe that for pixels having Std Deviation below 30 are all Covid Positive Images (Orange Colored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:15.445338Z",
     "iopub.status.busy": "2022-02-21T11:31:15.444847Z",
     "iopub.status.idle": "2022-02-21T11:31:15.972441Z",
     "shell.execute_reply": "2022-02-21T11:31:15.971774Z",
     "shell.execute_reply.started": "2022-02-21T11:31:15.445299Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8));\n",
    "g = sns.FacetGrid(imageEDA, col = \"corona_result\", height = 5);\n",
    "g.map_dataframe(sns.scatterplot, x = 'mean', y = 'stedev');\n",
    "g.set_titles(col_template = \"{col_name}\", row_template= \"{row_name}\", size = 12);\n",
    "g.fig.subplots_adjust(top = .7);\n",
    "g.fig.suptitle('Mean and Standard Deviation of Image Samples', fontsize = 15);\n",
    "axes = g.axes.flatten();\n",
    "axes[0].set_ylabel('Standard Deviation');\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('\\nMean');\n",
    "g.fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing both Scatter plots, we observe that Postivie Samples have outliers (pixel points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Self Insights "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://raw.githubusercontent.com/Atharv-Chaudhari/Project-Covid/main/Phase%202%20Deep%20Learning/Images/Insights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:15.97409Z",
     "iopub.status.busy": "2022-02-21T11:31:15.973548Z",
     "iopub.status.idle": "2022-02-21T11:31:49.210152Z",
     "shell.execute_reply": "2022-02-21T11:31:49.209208Z",
     "shell.execute_reply.started": "2022-02-21T11:31:15.974053Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data = []\n",
    "\n",
    "# Storing images and their labels into a list for further Train Test split\n",
    "\n",
    "for i in range(len(data)):\n",
    "    image = cv2.imread(data['path'][i])\n",
    "    image = cv2.resize(image, (70, 70)) / 255.0\n",
    "    label = 1 if data['corona_result'][i] == \"Positive\" else 0\n",
    "    all_data.append([image, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:49.213547Z",
     "iopub.status.busy": "2022-02-21T11:31:49.213328Z",
     "iopub.status.idle": "2022-02-21T11:31:50.543034Z",
     "shell.execute_reply": "2022-02-21T11:31:50.542208Z",
     "shell.execute_reply.started": "2022-02-21T11:31:49.213521Z"
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for image, label in all_data:\n",
    "    x.append(image)\n",
    "    y.append(label)\n",
    "\n",
    "# Converting to Numpy Array    \n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 42)\n",
    "\n",
    "print(x_train.shape, x_test.shape, x_val.shape, y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:50.544772Z",
     "iopub.status.busy": "2022-02-21T11:31:50.544528Z",
     "iopub.status.idle": "2022-02-21T11:31:52.835142Z",
     "shell.execute_reply": "2022-02-21T11:31:52.834418Z",
     "shell.execute_reply.started": "2022-02-21T11:31:50.544739Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential()\n",
    "cnn_model.add(layers.Conv2D(filters = 128, kernel_size = (3, 3), activation = 'relu', input_shape = (70, 70, 3)))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Dropout(0.3))\n",
    "\n",
    "cnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "cnn_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn_model.add(layers.Dropout(0.5))\n",
    "\n",
    "cnn_model.add(layers.Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "cnn_model.add(layers.Flatten())\n",
    "cnn_model.add(layers.Dense(units = 16, activation = 'relu'))\n",
    "cnn_model.add(layers.Dropout(0.2))\n",
    "\n",
    "cnn_model.add(layers.Dense(units = 2))\n",
    "\n",
    "cnn_model.compile(optimizer = 'adam', \n",
    "           loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True), \n",
    "           metrics = ['accuracy'])\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:31:52.836507Z",
     "iopub.status.busy": "2022-02-21T11:31:52.836275Z",
     "iopub.status.idle": "2022-02-21T11:33:10.988721Z",
     "shell.execute_reply": "2022-02-21T11:33:10.987941Z",
     "shell.execute_reply.started": "2022-02-21T11:31:52.836473Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 4)\n",
    "\n",
    "#tf.random.set_seed(42)\n",
    "history = cnn_model.fit(x_train, y_train, \n",
    "                        epochs = 50, batch_size = 256,  \n",
    "                        validation_data = (x_val, y_val), \n",
    "                        callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:10.992809Z",
     "iopub.status.busy": "2022-02-21T11:33:10.992599Z",
     "iopub.status.idle": "2022-02-21T11:33:19.300233Z",
     "shell.execute_reply": "2022-02-21T11:33:19.299488Z",
     "shell.execute_reply.started": "2022-02-21T11:33:10.992783Z"
    }
   },
   "outputs": [],
   "source": [
    "yp_train = cnn_model.predict(x_train)\n",
    "yp_train = np.argmax(yp_train, axis = 1)\n",
    "\n",
    "yp_val = cnn_model.predict(x_val)\n",
    "yp_val = np.argmax(yp_val, axis = 1)\n",
    "\n",
    "yp_test = cnn_model.predict(x_test)\n",
    "yp_test = np.argmax(yp_test, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:19.301842Z",
     "iopub.status.busy": "2022-02-21T11:33:19.30161Z",
     "iopub.status.idle": "2022-02-21T11:33:19.31669Z",
     "shell.execute_reply": "2022-02-21T11:33:19.316004Z",
     "shell.execute_reply.started": "2022-02-21T11:33:19.301809Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation_parametrics(name, y_train, yp_train, y_val, yp_val, y_test, yp_test):\n",
    "    \n",
    "    print(\"\\n-----------------------------{}-----------------------------\\n\".format(name))\n",
    "    \n",
    "    cm_train = confusion_matrix(y_train, yp_train)\n",
    "    t1 = ConfusionMatrixDisplay(cm_train)\n",
    "    s1 = round((cm_train[0,0]/(cm_train[0,0] + cm_train[0,1])),4)\n",
    "    \n",
    "    print(\"Classification Report for Train Data\\n\")\n",
    "    print(classification_report(y_train, yp_train)) \n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"Recall on Train Data: \", round(recall_score(y_train, yp_train),4))\n",
    "    print(\"Specificity on Train Data: \", s1)\n",
    "    print(\"Accuracy on Train Data: \", round(accuracy_score(y_train, yp_train),4))\n",
    "    print(\"Precision on Train Data: \", round(precision_score(y_train, yp_train),4))\n",
    "    print(\"F1 Score on Train Data: \", round(f1_score(y_train, yp_train),4))\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "       \n",
    "    cm_val = confusion_matrix(y_val, yp_val)\n",
    "    t2 = ConfusionMatrixDisplay(cm_val)\n",
    "    s2 = round((cm_val[0,0]/(cm_val[0,0] + cm_val[0,1])),4)\n",
    "    \n",
    "    print(\"\\nClassification Report for Validation Data\\n\")\n",
    "    print(classification_report(y_val, yp_val))   \n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"Recall on Val Data: \", round(recall_score(y_val, yp_val),4))\n",
    "    print(\"Specificity on Val Data: \", s2)\n",
    "    print(\"Accuracy on Val Data: \", round(accuracy_score(y_val, yp_val),4))\n",
    "    print(\"Precision on Val Data: \", round(precision_score(y_val, yp_val),4))\n",
    "    print(\"F1 Score on Val Data: \", round(f1_score(y_val, yp_val),4))\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    cm_test = confusion_matrix(y_test, yp_test)\n",
    "    t3 = ConfusionMatrixDisplay(cm_test)\n",
    "    s3 = round((cm_test[0,0]/(cm_test[0,0] + cm_test[0,1])),4)\n",
    "    \n",
    "    print(\"\\nClassification Report for Test Data\\n\")\n",
    "    print(classification_report(y_test, yp_test))   \n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    print(\"Recall on Test Data: \", round(recall_score(y_test, yp_test), 4))\n",
    "    print(\"Specificity on Test Data: \", s3)\n",
    "    print(\"Accuracy on Test Data: \", round(accuracy_score(y_test, yp_test), 4))\n",
    "    print(\"Precision on Test Data: \", round(precision_score(y_test, yp_test), 4))\n",
    "    print(\"F1 Score Test Data: \", round(f1_score(y_test, yp_test), 4))\n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "    \n",
    "    t1.plot()\n",
    "    t2.plot()   \n",
    "    t3.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:19.31945Z",
     "iopub.status.busy": "2022-02-21T11:33:19.317911Z",
     "iopub.status.idle": "2022-02-21T11:33:19.953583Z",
     "shell.execute_reply": "2022-02-21T11:33:19.952876Z",
     "shell.execute_reply.started": "2022-02-21T11:33:19.319411Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation_parametrics(\"Convolution Neural Network\", y_train, yp_train, y_val, yp_val, y_test, yp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:19.955278Z",
     "iopub.status.busy": "2022-02-21T11:33:19.954999Z",
     "iopub.status.idle": "2022-02-21T11:33:19.960437Z",
     "shell.execute_reply": "2022-02-21T11:33:19.959603Z",
     "shell.execute_reply.started": "2022-02-21T11:33:19.955242Z"
    }
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:19.9625Z",
     "iopub.status.busy": "2022-02-21T11:33:19.962191Z",
     "iopub.status.idle": "2022-02-21T11:33:20.452399Z",
     "shell.execute_reply": "2022-02-21T11:33:20.451725Z",
     "shell.execute_reply.started": "2022-02-21T11:33:19.962423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize History for Accuracy\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:20.453979Z",
     "iopub.status.busy": "2022-02-21T11:33:20.453438Z",
     "iopub.status.idle": "2022-02-21T11:33:20.627945Z",
     "shell.execute_reply": "2022-02-21T11:33:20.62731Z",
     "shell.execute_reply.started": "2022-02-21T11:33:20.453939Z"
    }
   },
   "outputs": [],
   "source": [
    "# Summarize History for Loss\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:20.631929Z",
     "iopub.status.busy": "2022-02-21T11:33:20.631741Z",
     "iopub.status.idle": "2022-02-21T11:33:20.835562Z",
     "shell.execute_reply": "2022-02-21T11:33:20.834867Z",
     "shell.execute_reply.started": "2022-02-21T11:33:20.631905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy Loss Graph\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.title('Model Accuracy/Loss')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We observe that Train & Validation Accuracy's Curve slightly overlap and same with Loss Curve. \n",
    "\n",
    "> Hence, Overfitting is avoided, this is possible because of Dropout Regularization & Early Stopping Metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Analysis using Grad-CAM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config- Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:20.837481Z",
     "iopub.status.busy": "2022-02-21T11:33:20.836971Z",
     "iopub.status.idle": "2022-02-21T11:33:20.843136Z",
     "shell.execute_reply": "2022-02-21T11:33:20.842478Z",
     "shell.execute_reply.started": "2022-02-21T11:33:20.837441Z"
    }
   },
   "outputs": [],
   "source": [
    "model_builder = keras.applications.xception.Xception\n",
    "img_size = (299, 299)\n",
    "preprocess_input = keras.applications.xception.preprocess_input\n",
    "decode_predictions = keras.applications.xception.decode_predictions\n",
    "imag = []\n",
    "\n",
    "last_conv_layer_name = \"block14_sepconv2_act\"\n",
    "\n",
    "# Reading 2 Covid & 2 Normal Images for Grad-Cam Analysis\n",
    "\n",
    "img_path = [\"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/COVID-1002.png\",\n",
    "            \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/COVID/COVID-101.png\",\n",
    "            \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/Normal-10004.png\",\n",
    "           \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/Normal/Normal-10002.png\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grad - CAM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:20.844518Z",
     "iopub.status.busy": "2022-02-21T11:33:20.844202Z",
     "iopub.status.idle": "2022-02-21T11:33:20.856216Z",
     "shell.execute_reply": "2022-02-21T11:33:20.85535Z",
     "shell.execute_reply.started": "2022-02-21T11:33:20.844483Z"
    }
   },
   "outputs": [],
   "source": [
    "# To Get Image into numpy array\n",
    "\n",
    "def get_img_array(img_path, size):\n",
    "    img = keras.preprocessing.image.load_img(img_path, target_size = size) \n",
    "    array = keras.preprocessing.image.img_to_array(img) \n",
    "    array = np.expand_dims(array, axis = 0)\n",
    "    return array\n",
    "\n",
    "# Top create heatmaps for the samples\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index = None):\n",
    "    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:20.857665Z",
     "iopub.status.busy": "2022-02-21T11:33:20.857401Z",
     "iopub.status.idle": "2022-02-21T11:33:29.450817Z",
     "shell.execute_reply": "2022-02-21T11:33:29.450074Z",
     "shell.execute_reply.started": "2022-02-21T11:33:20.857631Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing Heatmap values into list\n",
    "\n",
    "covid_noncovid_heatmap = []\n",
    "\n",
    "for i in img_path:\n",
    "    img_array = preprocess_input(get_img_array(i, size = img_size))\n",
    "    model = model_builder(weights = \"imagenet\")\n",
    "    model.layers[-1].activation = None\n",
    "    preds = model.predict(img_array)\n",
    "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "    covid_noncovid_heatmap.append(heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Superimposed Viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:29.452304Z",
     "iopub.status.busy": "2022-02-21T11:33:29.452065Z",
     "iopub.status.idle": "2022-02-21T11:33:29.511988Z",
     "shell.execute_reply": "2022-02-21T11:33:29.511283Z",
     "shell.execute_reply.started": "2022-02-21T11:33:29.452273Z"
    }
   },
   "outputs": [],
   "source": [
    "# To Display GradCAM output for the samples\n",
    "\n",
    "def save_and_display_gradcam(img_path, heatmap, cam_path = \"cam.jpg\", alpha = 0.4):\n",
    "    img = keras.preprocessing.image.load_img(img_path)\n",
    "    img = keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    superimposed_img.save(cam_path)\n",
    "    \n",
    "    imag.append(cv2.imread(img_path))\n",
    "    imag.append(cv2.imread(\"./cam.jpg\"))\n",
    "\n",
    "\n",
    "for i in range(len(img_path)):\n",
    "    save_and_display_gradcam(img_path[i], covid_noncovid_heatmap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:29.51499Z",
     "iopub.status.busy": "2022-02-21T11:33:29.514793Z",
     "iopub.status.idle": "2022-02-21T11:33:30.376998Z",
     "shell.execute_reply": "2022-02-21T11:33:30.376371Z",
     "shell.execute_reply.started": "2022-02-21T11:33:29.514966Z"
    }
   },
   "outputs": [],
   "source": [
    "titles_list = [\"Positive-1\",'Positive-1 Grad','Positive-2','Positive-2 Grad','Negative-1','Negative-1 Grad','Negative-2','Negative-2 Grad']\n",
    "\n",
    "plot_multiple_img(imag, titles_list, ncols = 4, main_title = \"GRAD-CAM COVID-19 Image Analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Positive-1 Sample Insight: In its Grad-CAM image on the right mid part of it we can see the blue color highlighted portion which is opacity due to which it belongs to COVID - Positive Category.\n",
    "\n",
    "> Positive-2 Sample Insight: In its Grad-CAM image on the left bottom part of it we can see the blue green color highlighted portion which is consolidation and no Tree-Bud due to which it belongs to COVID - Positive Category.\n",
    "\n",
    "> Negative-1 Sample Insight: In its Grad-CAM image we can see the blue color highlighted portion which is between the Cardiac and Diaphragm and no any opacity was detected due to which it belongs to COVID - Negative Category.\n",
    "\n",
    "> Negative-2 Sample Insight: In its Grad-CAM image we can see the blue color portion which highlights the Trachea and no other opacity was detected due to which it belongs to COVID - Negative Category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:30.378835Z",
     "iopub.status.busy": "2022-02-21T11:33:30.378161Z",
     "iopub.status.idle": "2022-02-21T11:33:30.561742Z",
     "shell.execute_reply": "2022-02-21T11:33:30.561046Z",
     "shell.execute_reply.started": "2022-02-21T11:33:30.378797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking predictions for the above sample images\n",
    "\n",
    "for i in img_path:\n",
    "    z_img = cv2.imread(i)\n",
    "    z_img = cv2.resize(z_img, (70, 70)) / 255.0\n",
    "    z_img = z_img.reshape(1, z_img.shape[0], z_img.shape[1], z_img.shape[2])\n",
    "    \n",
    "    z = cnn_model.predict(z_img)\n",
    "    z = np.argmax(z, axis = 1)\n",
    "    print(\"Image\", img_path.index(i) + 1, \":\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T11:33:30.563432Z",
     "iopub.status.busy": "2022-02-21T11:33:30.563187Z",
     "iopub.status.idle": "2022-02-21T11:33:30.605566Z",
     "shell.execute_reply": "2022-02-21T11:33:30.604843Z",
     "shell.execute_reply.started": "2022-02-21T11:33:30.563396Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn_model.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. Done Exploratory Image Data Analysis on Covid vs Normal Images using various techniques.\n",
    "\n",
    "> 2. Applied Convolutional Neural Network Model and got good Accuracy and Loss and prevented Overfitting.\n",
    "\n",
    "> 3. Applied Grad - CAM Analysis on Sample Images and found few insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do upvote if you find this Notebook useful... ðŸ˜ƒ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
